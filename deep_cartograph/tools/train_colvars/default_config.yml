# cvs:                           List of Collective Variables to calculate: pca, ae, tica, deep_tica or htica
# common:                        Common settings for the Collective Variables
#   dimension:                    (int) Number of dimensions to calculate
#   lag_time:                     (int) Lag time for the Collective Variables
#   num_subspaces:                (int) Number of subspaces to calculate (only for htica) - increase to reduce the memory usage
#   subspaces_dimension:          (int) Dimension of the subspaces to calculate (only for htica) - reduce to reduce the memory usage
#   features_normalization:       (str) Normalization of the input features, e.g. 'mean_std', 'min_max_range1', 'min_max_range2', null
#   input_colvars:              Settings for the input colvars file reading with the time series of the input features
#     start:                      (int) Start index to read the input features (df.iloc[start:stop:stride])
#     stop:                       (int) Stop index to read the input features (df.iloc[start:stop:stride])
#     stride:                     (int) Stride to read the input features (df.iloc[start:stop:stride])
#   architecture:                 Settings for the architecture of the Collective Variables
#     encoder:              (list) Fully connected hidden layers between the input and latent space, e.g. [15, 15]
#   training:                    Settings for the training of the Collective Variables (when applicable)
#     general:                    General settings for the training
#       max_tries:                    (int) Maximum number of tries for the training
#       seed:                         (int) Seed for the PyTorch random number generator
#       lengths:                      (list) Lengths of the training and validation sets, e.g. [0.8, 0.2]
#       batch_size:                   (int) Batch size for the training
#       max_epochs:                   (int) Maximum number of epochs for the training
#       dropout:                      (float) Dropout rate for the training
#       shuffle:                      (bool) Shuffle the data before training 
#       check_val_every_n_epoch:      (int) Do a validation check every n epochs
#       save_check_every_n_epoch:     (int) Save the model every n epochs
#     early_stopping:              Settings for the early stopping
#       patience:                     (int) Patience for the early stopping, i.e., the number of validation checks with no improvement after which training will be stopped
#       min_delta:                    (float) Minimum change in the loss function to consider it an improvement
#     optimizer:                   Settings for the optimizer
#       name:                         (str) Name of the optimizer
#       kwargs:                       (dict) Keyword arguments for the optimizer
#     save_loss:                    (bool) Wether to save the training and validation losses after training 
#     plot_loss:                    (bool) Wether to plot the loss after training

cvs: ['pca', 'ae', 'tica', 'deep_tica']
common:
  dimension: 1
  lag_time: 10
  features_normalization: 'mean_std' # ['mean_std', 'min_max_range1', 'min_max_range2', null]
  input_colvars: 
    start: 0
    stop: null
    stride: 1 
  architecture:
    encoder: [15, 15]
  training:
    general:
      max_tries: 10
      seed: 42
      lengths: [0.8, 0.2]
      batch_size: 32
      max_epochs: 1000
      dropout: 0.1
      shuffle: False
      random_split: False
      check_val_every_n_epoch: 10
      save_check_every_n_epoch: 10
    early_stopping:
      patience: 2
      min_delta: 0.00001
    optimizer:
      name: Adam
      kwargs: 
        lr: 0.01
        weight_decay: 0.0
    save_loss: True
    plot_loss: True
  bias:
    method: wt_metadynamics
    args:
      sigma: 0.05
      height: 1.0
      bias_factor: 10.0
      temp: 300
      pace: 500
      grid_min: -1
      grid_max: 1
      grid_bin: 300
ae:
  training:
    general: 
      shuffle: True
      random_split: True
    optimizer:
      kwargs: 
        lr: 0.01
htica:
  num_subspaces: 10
  subspaces_dimension: 5

# figures:                          Settings for additional figures
#   fes:                              Settings for the Free Energy Surface calculation
#     compute:                          (bool) Calculate the Free Energy Surface
#     save:                             (bool) Save the calculated Free Energy Surface in .npy files (otherwise it just plots 1D or 2D FES)
#     temperature:                      (int) Temperature in Kelvin
#     bandwidth:                        (float) Bandwidth for the Kernel Density Estimation of the Free Energy Surface
#     num_bins:                         (int) Number of bins for the Kernel Density Estimation of the Free Energy Surface
#     max_fes:                          (float) Maximum value for the Free Energy Surface (above which the value is set to NaN)
#   traj_projection:                Settings for the Projected Trajectory
#     plot:                             (bool) Plot the Projected Trajectory
#     alpha:                            (float) Transparency of the points in the Projected Trajectory
#     cmap:                             (str) Colormap for the Projected Trajectory
#     marker_size:                      (int) Size of the markers in the Projected Trajectory

figures:
  fes:
    compute: True  
    save: True
    temperature: 300
    bandwidth: 0.01
    num_bins: 100
    num_blocks: 1
    max_fes: 40
  traj_projection:
    plot: True
    alpha: 0.6
    cmap: turbo
    marker_size: 12